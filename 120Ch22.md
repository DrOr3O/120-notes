# Beyond Physical Mem: Policies
- when page fauly happen
  - free mem: assign it to the fault page on the free page the list
  - little mem: mem pressure OS to start paging out pages to make room for actively used pages (replacement policy)

## Cache management:
- Given the main mem holds some subset of all the pages in the system, it can be viewed as a cashe for virtual mem page
  - We want to pick a policy that minimize the cache miss
- Average Memory Access Time = Time accessing mem + (Probability of miss * cost of accessing disk)

## Optimal Replacement:
- throw out the page we needed the furthest in terms of time 
- recall the misses: compulsory, capacity, conflict
- however this doesnt make any sense since usually we dont know the future of the system
  
## FIFO:
- Easy to implement, but the performance is meh
  
## Random policy:
- random pick the page to replace when mem pressure 
- the result is...random

## Using history: LRU:
- Using frequency, the history to help us
- FIFO and Random might kick out important page
- either use the frequency of the access or how recently it get access 
- recall locality: spatial and local

## Workload exmaples:
- When no locality is in the workload, the policy doesnt matter
  - hit rate solely determined by the size of the cache
- When cache is large enough to fit the entire workload
  - Policy also doesnt matter (perfect hit rate)
- 80/20 workload (80% of the reference made to 20% of the pages and 20% reference the 80%)
  - LRU wins out 
- Accessing 50 unique different pages
  - (worst case for LRU and FIFO)
  - Random did better

## Implementing Historical Algorithms
- LRU is hard to implement
- page access must update the data structure to the front of the list
- hardware support can help out the process (time field in mem on each access)
  - OS can just scan the field when page is accessed 

## Approximating LRU
- required hardware support (reference bit/used bit)
- whenever the page is referenced, use bit is set by hardware to 1
- **OS clears the bit not hardware**
- CLock algorithm
  - imagine all the pages in the system arranged in a circular list
  - Clock hand point to a random page to begin
  - When replacement occurs, OS check if the use bit is 1 or 0
    - If is 1 means is recently used not a good idea to swap
    - Set it to 0 and then keep finding the one that use bit is 0 already

## Considering Dirty pages
- modified pages going back to mem is very expensive
- thus we used dirty bit to indicate the page has been modified or not 
- clock algorithm can be changed to fit into this where use the both unused and unchanged to evict first 

## Other policies
- Page selecting: prefetch or on demand paging
- write out to the disk: clustering and grouping

## Thrashing:
- When mem demands are exceeds mem there are?
  - thrashing can happen where system constantly paging
- Could be dealt with either killed or systemetically control the amount of working process. 